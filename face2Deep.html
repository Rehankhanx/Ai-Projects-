<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI Body & Motion Analysis Scanner</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/pose-detection"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/coco-ssd"></script>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
        }
        
        body {
            background: linear-gradient(135deg, #0f2027, #203a43, #2c5364);
            color: #e0f7fa;
            min-height: 100vh;
            padding: 20px;
        }
        
        .container {
            max-width: 1400px;
            margin: 0 auto;
        }
        
        header {
            text-align: center;
            margin-bottom: 25px;
            padding: 20px;
            background: rgba(0, 30, 40, 0.7);
            border-radius: 15px;
            box-shadow: 0 8px 16px rgba(0, 0, 0, 0.3);
            border: 1px solid rgba(64, 224, 208, 0.3);
        }
        
        h1 {
            font-size: 2.8rem;
            margin-bottom: 10px;
            background: linear-gradient(90deg, #00b4d8, #90e0ef);
            -webkit-background-clip: text;
            background-clip: text;
            color: transparent;
            text-shadow: 0 2px 4px rgba(0, 0, 0, 0.3);
        }
        
        .tagline {
            font-size: 1.2rem;
            color: #a8e6cf;
            margin-bottom: 15px;
        }
        
        .main-content {
            display: flex;
            flex-wrap: wrap;
            gap: 20px;
            margin-bottom: 25px;
        }
        
        .video-section {
            flex: 1;
            min-width: 500px;
            background: rgba(0, 30, 40, 0.7);
            border-radius: 15px;
            padding: 20px;
            box-shadow: 0 8px 16px rgba(0, 0, 0, 0.3);
            border: 1px solid rgba(64, 224, 208, 0.3);
        }
        
        .analysis-section {
            flex: 1;
            min-width: 500px;
            background: rgba(0, 30, 40, 0.7);
            border-radius: 15px;
            padding: 20px;
            box-shadow: 0 8px 16px rgba(0, 0, 0, 0.3);
            border: 1px solid rgba(64, 224, 208, 0.3);
        }
        
        .section-title {
            font-size: 1.5rem;
            margin-bottom: 15px;
            color: #00b4d8;
            border-bottom: 2px solid rgba(0, 180, 216, 0.5);
            padding-bottom: 8px;
            display: flex;
            align-items: center;
            gap: 10px;
        }
        
        .section-title i {
            font-size: 1.3rem;
        }
        
        .video-container {
            position: relative;
            width: 100%;
            height: 360px;
            background: #000;
            border-radius: 10px;
            overflow: hidden;
            margin-bottom: 15px;
            border: 2px solid rgba(64, 224, 208, 0.5);
        }
        
        #videoElement {
            width: 100%;
            height: 100%;
            object-fit: cover;
        }
        
        #canvasElement {
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            z-index: 10;
        }
        
        .controls {
            display: flex;
            flex-wrap: wrap;
            gap: 10px;
            margin-bottom: 20px;
        }
        
        .control-btn {
            flex: 1;
            min-width: 120px;
            padding: 12px 15px;
            background: linear-gradient(135deg, #0077b6, #0096c7);
            color: white;
            border: none;
            border-radius: 8px;
            font-weight: 600;
            font-size: 1rem;
            cursor: pointer;
            transition: all 0.3s;
            display: flex;
            align-items: center;
            justify-content: center;
            gap: 8px;
        }
        
        .control-btn:hover {
            background: linear-gradient(135deg, #0096c7, #00b4d8);
            transform: translateY(-2px);
            box-shadow: 0 5px 10px rgba(0, 150, 199, 0.4);
        }
        
        .control-btn:active {
            transform: translateY(1px);
        }
        
        .control-btn.primary {
            background: linear-gradient(135deg, #023e8a, #0077b6);
        }
        
        .control-btn.danger {
            background: linear-gradient(135deg, #d00000, #dc2f02);
        }
        
        .control-btn.success {
            background: linear-gradient(135deg, #2d6a4f, #40916c);
        }
        
        .analysis-results {
            height: 360px;
            overflow-y: auto;
            padding-right: 10px;
        }
        
        .analysis-item {
            background: rgba(0, 40, 50, 0.5);
            border-radius: 10px;
            padding: 15px;
            margin-bottom: 15px;
            border-left: 4px solid #00b4d8;
        }
        
        .analysis-item h3 {
            font-size: 1.1rem;
            margin-bottom: 8px;
            color: #90e0ef;
            display: flex;
            align-items: center;
            gap: 8px;
        }
        
        .analysis-item p {
            color: #caf0f8;
            line-height: 1.5;
        }
        
        .analysis-item .status {
            display: inline-block;
            padding: 4px 10px;
            border-radius: 20px;
            font-size: 0.85rem;
            font-weight: 600;
            margin-top: 8px;
        }
        
        .status.detected {
            background: rgba(72, 187, 120, 0.2);
            color: #48bb78;
        }
        
        .status.analyzing {
            background: rgba(246, 173, 85, 0.2);
            color: #f6ad55;
        }
        
        .status.ready {
            background: rgba(66, 153, 225, 0.2);
            color: #4299e1;
        }
        
        .captured-images {
            display: grid;
            grid-template-columns: repeat(auto-fill, minmax(150px, 1fr));
            gap: 15px;
            margin-top: 15px;
        }
        
        .captured-image {
            position: relative;
            border-radius: 8px;
            overflow: hidden;
            box-shadow: 0 4px 8px rgba(0, 0, 0, 0.2);
            border: 2px solid rgba(64, 224, 208, 0.3);
            transition: transform 0.3s;
        }
        
        .captured-image:hover {
            transform: scale(1.05);
        }
        
        .captured-image img {
            width: 100%;
            height: 120px;
            object-fit: cover;
        }
        
        .image-info {
            padding: 8px;
            background: rgba(0, 20, 30, 0.8);
            font-size: 0.8rem;
        }
        
        .footer {
            text-align: center;
            margin-top: 20px;
            padding: 15px;
            color: #90e0ef;
            font-size: 0.9rem;
            background: rgba(0, 30, 40, 0.7);
            border-radius: 10px;
        }
        
        .loading {
            display: flex;
            justify-content: center;
            align-items: center;
            height: 100%;
            font-size: 1.2rem;
            color: #00b4d8;
        }
        
        .loading i {
            margin-right: 10px;
            animation: spin 2s linear infinite;
        }
        
        @keyframes spin {
            0% { transform: rotate(0deg); }
            100% { transform: rotate(360deg); }
        }
        
        .hidden {
            display: none;
        }
        
        /* Scrollbar styling */
        ::-webkit-scrollbar {
            width: 8px;
        }
        
        ::-webkit-scrollbar-track {
            background: rgba(0, 40, 50, 0.5);
            border-radius: 4px;
        }
        
        ::-webkit-scrollbar-thumb {
            background: #00b4d8;
            border-radius: 4px;
        }
        
        /* Responsive adjustments */
        @media (max-width: 1100px) {
            .main-content {
                flex-direction: column;
            }
            
            .video-section, .analysis-section {
                min-width: 100%;
            }
        }
        
        @media (max-width: 600px) {
            h1 {
                font-size: 2rem;
            }
            
            .video-container {
                height: 280px;
            }
            
            .analysis-results {
                height: 300px;
            }
            
            .control-btn {
                min-width: 100%;
            }
        }
    </style>
</head>
<body>
    <div class="container">
        <header>
            <h1><i class="fas fa-robot"></i> AI Body & Motion Analysis Scanner</h1>
            <p class="tagline">Real-time analysis of body structure, movement patterns, and object detection</p>
            <p>Analyzes walking, running, jumping, fighting, cycling, and object motion detection</p>
        </header>
        
        <div class="main-content">
            <section class="video-section">
                <h2 class="section-title"><i class="fas fa-video"></i> Live Scanner</h2>
                
                <div class="video-container">
                    <video id="videoElement" autoplay playsinline></video>
                    <canvas id="canvasElement"></canvas>
                    <div id="loadingIndicator" class="loading">
                        <i class="fas fa-spinner"></i> Loading AI models...
                    </div>
                </div>
                
                <div class="controls">
                    <button id="startButton" class="control-btn primary">
                        <i class="fas fa-play"></i> Start Scanner
                    </button>
                    <button id="captureButton" class="control-btn success">
                        <i class="fas fa-camera"></i> Capture Image
                    </button>
                    <button id="toggleModelsButton" class="control-btn">
                        <i class="fas fa-exchange-alt"></i> Toggle Detection
                    </button>
                    <button id="clearButton" class="control-btn danger">
                        <i class="fas fa-trash-alt"></i> Clear Images
                    </button>
                </div>
                
                <div id="capturedImagesContainer">
                    <h3 class="section-title"><i class="fas fa-images"></i> Captured Images</h3>
                    <div id="capturedImages" class="captured-images">
                        <!-- Captured images will appear here -->
                    </div>
                </div>
            </section>
            
            <section class="analysis-section">
                <h2 class="section-title"><i class="fas fa-chart-line"></i> Analysis Results</h2>
                
                <div id="analysisResults" class="analysis-results">
                    <div class="analysis-item">
                        <h3><i class="fas fa-walking"></i> Body Pose Analysis</h3>
                        <p>Waiting for video input. Body keypoints will be detected and analyzed for posture, balance, and movement patterns.</p>
                        <span class="status ready">Ready</span>
                    </div>
                    
                    <div class="analysis-item">
                        <h3><i class="fas fa-running"></i> Motion Pattern Recognition</h3>
                        <p>Movement patterns will be classified as walking, running, jumping, fighting, cycling, or other activities based on joint movement analysis.</p>
                        <span class="status ready">Ready</span>
                    </div>
                    
                    <div class="analysis-item">
                        <h3><i class="fas fa-cube"></i> Object Detection</h3>
                        <p>Objects in the frame will be identified with bounding boxes and labels. Motion vectors will be calculated for moving objects.</p>
                        <span class="status ready">Ready</span>
                    </div>
                    
                    <div class="analysis-item">
                        <h3><i class="fas fa-heartbeat"></i> Body Structure Analysis</h3>
                        <p>Body proportions, symmetry, and structural alignment will be evaluated based on detected keypoints.</p>
                        <span class="status ready">Ready</span>
                    </div>
                </div>
                
                <div class="controls" style="margin-top: 20px;">
                    <button id="analyzeButton" class="control-btn primary">
                        <i class="fas fa-search"></i> Run Deep Analysis
                    </button>
                    <button id="exportButton" class="control-btn success">
                        <i class="fas fa-file-export"></i> Export Data
                    </button>
                </div>
            </section>
        </div>
        
        <footer class="footer">
            <p>AI Body & Motion Analysis Scanner | Uses TensorFlow.js for pose detection and object recognition | All processing happens locally in your browser</p>
            <p style="margin-top: 5px; font-size: 0.8rem;">Note: This is a demonstration. For production use, additional AI models and optimization would be required.</p>
        </footer>
    </div>

    <script>
        // Global variables
        let videoStream = null;
        let poseDetector = null;
        let objectDetector = null;
        let isScanning = false;
        let animationId = null;
        let capturedImages = [];
        let usePoseDetection = true;
        let lastAnalysisTime = 0;
        
        // DOM elements
        const videoElement = document.getElementById('videoElement');
        const canvasElement = document.getElementById('canvasElement');
        const canvasContext = canvasElement.getContext('2d');
        const startButton = document.getElementById('startButton');
        const captureButton = document.getElementById('captureButton');
        const toggleModelsButton = document.getElementById('toggleModelsButton');
        const clearButton = document.getElementById('clearButton');
        const analyzeButton = document.getElementById('analyzeButton');
        const exportButton = document.getElementById('exportButton');
        const loadingIndicator = document.getElementById('loadingIndicator');
        const capturedImagesContainer = document.getElementById('capturedImages');
        const analysisResults = document.getElementById('analysisResults');
        
        // Initialize the application
        async function init() {
            try {
                // Load AI models
                await loadAIModels();
                
                // Set up event listeners
                setupEventListeners();
                
                // Update UI
                loadingIndicator.classList.add('hidden');
                startButton.disabled = false;
                captureButton.disabled = false;
                
                console.log("AI Scanner initialized successfully");
            } catch (error) {
                console.error("Error initializing AI Scanner:", error);
                loadingIndicator.innerHTML = `<i class="fas fa-exclamation-triangle"></i> Error loading AI models. Please refresh.`;
            }
        }
        
        // Load TensorFlow.js AI models
        async function loadAIModels() {
            console.log("Loading AI models...");
            
            // Load Pose Detection model (MoveNet)
            try {
                const detectorConfig = {
                    modelType: poseDetection.movenet.modelType.SINGLEPOSE_THUNDER,
                    enableSmoothing: true,
                    minPoseScore: 0.3
                };
                poseDetector = await poseDetection.createDetector(
                    poseDetection.SupportedModels.MoveNet,
                    detectorConfig
                );
                console.log("Pose detection model loaded successfully");
            } catch (error) {
                console.warn("Could not load pose detection model:", error);
                // Fallback to simulated pose detection for demo purposes
                console.log("Using simulated pose detection for demo");
            }
            
            // Load Object Detection model (COCO-SSD)
            try {
                objectDetector = await cocoSsd.load();
                console.log("Object detection model loaded successfully");
            } catch (error) {
                console.warn("Could not load object detection model:", error);
                // Fallback to simulated object detection for demo purposes
                console.log("Using simulated object detection for demo");
            }
        }
        
        // Set up event listeners
        function setupEventListeners() {
            startButton.addEventListener('click', toggleScanner);
            captureButton.addEventListener('click', captureImage);
            toggleModelsButton.addEventListener('click', toggleDetectionMode);
            clearButton.addEventListener('click', clearCapturedImages);
            analyzeButton.addEventListener('click', runDeepAnalysis);
            exportButton.addEventListener('click', exportData);
        }
        
        // Toggle scanner on/off
        async function toggleScanner() {
            if (!isScanning) {
                // Start scanner
                try {
                    videoStream = await navigator.mediaDevices.getUserMedia({
                        video: { 
                            width: { ideal: 640 },
                            height: { ideal: 480 },
                            facingMode: "user"
                        }
                    });
                    
                    videoElement.srcObject = videoStream;
                    
                    // Set canvas dimensions to match video
                    videoElement.onloadedmetadata = () => {
                        canvasElement.width = videoElement.videoWidth;
                        canvasElement.height = videoElement.videoHeight;
                    };
                    
                    isScanning = true;
                    startButton.innerHTML = '<i class="fas fa-stop"></i> Stop Scanner';
                    startButton.classList.add('danger');
                    startButton.classList.remove('primary');
                    captureButton.disabled = false;
                    toggleModelsButton.disabled = false;
                    
                    // Start the detection loop
                    detect();
                } catch (error) {
                    console.error("Error accessing webcam:", error);
                    alert("Could not access webcam. Please check permissions and try again.");
                }
            } else {
                // Stop scanner
                if (videoStream) {
                    videoStream.getTracks().forEach(track => track.stop());
                    videoStream = null;
                }
                
                isScanning = false;
                startButton.innerHTML = '<i class="fas fa-play"></i> Start Scanner';
                startButton.classList.remove('danger');
                startButton.classList.add('primary');
                captureButton.disabled = true;
                
                // Stop animation loop
                if (animationId) {
                    cancelAnimationFrame(animationId);
                    animationId = null;
                }
                
                // Clear canvas
                canvasContext.clearRect(0, 0, canvasElement.width, canvasElement.height);
            }
        }
        
        // Toggle between pose and object detection
        function toggleDetectionMode() {
            usePoseDetection = !usePoseDetection;
            toggleModelsButton.innerHTML = usePoseDetection ? 
                '<i class="fas fa-exchange-alt"></i> Switch to Object Detection' : 
                '<i class="fas fa-exchange-alt"></i> Switch to Pose Detection';
            
            // Update status in analysis panel
            updateAnalysisPanel();
        }
        
        // Main detection loop
        async function detect() {
            if (!isScanning) return;
            
            // Clear canvas
            canvasContext.clearRect(0, 0, canvasElement.width, canvasElement.height);
            
            // Draw video frame to canvas
            canvasContext.drawImage(videoElement, 0, 0, canvasElement.width, canvasElement.height);
            
            // Run detection based on current mode
            if (usePoseDetection) {
                await detectPoses();
            } else {
                await detectObjects();
            }
            
            // Continue the loop
            animationId = requestAnimationFrame(detect);
            
            // Update analysis panel periodically (every 2 seconds)
            const now = Date.now();
            if (now - lastAnalysisTime > 2000) {
                updateAnalysisPanel();
                lastAnalysisTime = now;
            }
        }
        
        // Detect body poses
        async function detectPoses() {
            try {
                let poses = [];
                
                if (poseDetector) {
                    // Use real pose detector if available
                    poses = await poseDetector.estimatePoses(videoElement, {
                        maxPoses: 2,
                        flipHorizontal: false
                    });
                } else {
                    // Simulated pose detection for demo
                    poses = getSimulatedPoses();
                }
                
                // Draw poses on canvas
                drawPoses(poses);
                
                // Update analysis with pose data
                updatePoseAnalysis(poses);
                
            } catch (error) {
                console.error("Error detecting poses:", error);
            }
        }
        
        // Detect objects
        async function detectObjects() {
            try {
                let objects = [];
                
                if (objectDetector) {
                    // Use real object detector if available
                    objects = await objectDetector.detect(videoElement);
                } else {
                    // Simulated object detection for demo
                    objects = getSimulatedObjects();
                }
                
                // Draw objects on canvas
                drawObjects(objects);
                
                // Update analysis with object data
                updateObjectAnalysis(objects);
                
            } catch (error) {
                console.error("Error detecting objects:", error);
            }
        }
        
        // Draw poses on canvas
        function drawPoses(poses) {
            if (!poses || poses.length === 0) return;
            
            // Define pose connections (skeleton)
            const connections = [
                // Head and torso
                ['nose', 'left_eye'], ['nose', 'right_eye'],
                ['left_eye', 'left_ear'], ['right_eye', 'right_ear'],
                ['left_shoulder', 'right_shoulder'],
                ['left_shoulder', 'left_hip'], ['right_shoulder', 'right_hip'],
                ['left_hip', 'right_hip'],
                
                // Arms
                ['left_shoulder', 'left_elbow'], ['left_elbow', 'left_wrist'],
                ['right_shoulder', 'right_elbow'], ['right_elbow', 'right_wrist'],
                
                // Legs
                ['left_hip', 'left_knee'], ['left_knee', 'left_ankle'],
                ['right_hip', 'right_knee'], ['right_knee', 'right_ankle']
            ];
            
            poses.forEach(pose => {
                const keypoints = pose.keypoints;
                
                // Draw skeleton connections
                connections.forEach(connection => {
                    const [start, end] = connection;
                    const startPoint = keypoints.find(kp => kp.name === start);
                    const endPoint = keypoints.find(kp => kp.name === end);
                    
                    if (startPoint && endPoint && startPoint.score > 0.3 && endPoint.score > 0.3) {
                        canvasContext.beginPath();
                        canvasContext.moveTo(startPoint.x, startPoint.y);
                        canvasContext.lineTo(endPoint.x, endPoint.y);
                        canvasContext.lineWidth = 3;
                        canvasContext.strokeStyle = '#00ffaa';
                        canvasContext.stroke();
                    }
                });
                
                // Draw keypoints
                keypoints.forEach(keypoint => {
                    if (keypoint.score > 0.3) {
                        canvasContext.beginPath();
                        canvasContext.arc(keypoint.x, keypoint.y, 5, 0, 2 * Math.PI);
                        canvasContext.fillStyle = '#ff0080';
                        canvasContext.fill();
                        
                        // Draw keypoint label
                        canvasContext.font = '12px Arial';
                        canvasContext.fillStyle = '#ffffff';
                        canvasContext.fillText(keypoint.name, keypoint.x + 7, keypoint.y - 7);
                    }
                });
            });
        }
        
        // Draw objects on canvas
        function drawObjects(objects) {
            objects.forEach(object => {
                const [x, y, width, height] = object.bbox;
                
                // Draw bounding box
                canvasContext.beginPath();
                canvasContext.rect(x, y, width, height);
                canvasContext.lineWidth = 2;
                canvasContext.strokeStyle = '#ffaa00';
                canvasContext.stroke();
                
                // Draw label background
                canvasContext.fillStyle = 'rgba(255, 170, 0, 0.7)';
                const textWidth = canvasContext.measureText(`${object.class}: ${(object.score * 100).toFixed(1)}%`).width;
                canvasContext.fillRect(x, y - 20, textWidth + 10, 20);
                
                // Draw label text
                canvasContext.font = '14px Arial';
                canvasContext.fillStyle = '#000000';
                canvasContext.fillText(`${object.class}: ${(object.score * 100).toFixed(1)}%`, x + 5, y - 5);
            });
        }
        
        // Capture image from video
        function captureImage() {
            if (!isScanning) return;
            
            // Create a temporary canvas to capture the current frame
            const tempCanvas = document.createElement('canvas');
            tempCanvas.width = canvasElement.width;
            tempCanvas.height = canvasElement.height;
            const tempContext = tempCanvas.getContext('2d');
            
            // Draw current video frame with overlays
            tempContext.drawImage(videoElement, 0, 0, tempCanvas.width, tempCanvas.height);
            
            if (usePoseDetection) {
                // Draw poses on the captured image
                // (In a real implementation, we would recalculate poses for this frame)
                tempContext.drawImage(canvasElement, 0, 0);
            } else {
                // Draw objects on the captured image
                tempContext.drawImage(canvasElement, 0, 0);
            }
            
            // Convert to data URL
            const imageDataUrl = tempCanvas.toDataURL('image/jpeg', 0.9);
            
            // Add to captured images array
            const timestamp = new Date().toISOString().replace(/[:.]/g, '-');
            const imageInfo = {
                id: `capture_${timestamp}`,
                dataUrl: imageDataUrl,
                timestamp: new Date().toLocaleString(),
                detectionMode: usePoseDetection ? 'pose' : 'object',
                analysis: getCurrentAnalysis()
            };
            
            capturedImages.unshift(imageInfo);
            
            // Update UI
            renderCapturedImages();
            
            // Show notification
            showNotification(`Image captured successfully! (${capturedImages.length} total)`);
        }
        
        // Render captured images in the UI
        function renderCapturedImages() {
            capturedImagesContainer.innerHTML = '';
            
            if (capturedImages.length === 0) {
                capturedImagesContainer.innerHTML = '<p style="text-align: center; padding: 20px; color: #90e0ef;">No images captured yet</p>';
                return;
            }
            
            // Show only the last 6 images
            const imagesToShow = capturedImages.slice(0, 6);
            
            imagesToShow.forEach(image => {
                const imageElement = document.createElement('div');
                imageElement.className = 'captured-image';
                imageElement.innerHTML = `
                    <img src="${image.dataUrl}" alt="Captured Image">
                    <div class="image-info">
                        <div>${image.timestamp}</div>
                        <div>${image.detectionMode === 'pose' ? 'Pose' : 'Object'} Detection</div>
                    </div>
                `;
                
                // Add click event to view larger
                imageElement.addEventListener('click', () => {
                    viewImage(image);
                });
                
                capturedImagesContainer.appendChild(imageElement);
            });
        }
        
        // View image in larger view
        function viewImage(image) {
            // In a more complete implementation, this would open a modal
            // For this demo, we'll just show an alert
            alert(`Image captured at: ${image.timestamp}\nDetection mode: ${image.detectionMode}\n\nAnalysis summary:\n${JSON.stringify(image.analysis, null, 2)}`);
        }
        
        // Clear all captured images
        function clearCapturedImages() {
            if (capturedImages.length === 0) return;
            
            if (confirm(`Are you sure you want to delete all ${capturedImages.length} captured images?`)) {
                capturedImages = [];
                renderCapturedImages();
                showNotification("All captured images have been deleted");
            }
        }
        
        // Run deep analysis
        function runDeepAnalysis() {
            if (!isScanning) {
                alert("Please start the scanner first to run analysis");
                return;
            }
            
            // Show analyzing status
            analyzeButton.innerHTML = '<i class="fas fa-spinner fa-spin"></i> Analyzing...';
            analyzeButton.disabled = true;
            
            // Simulate analysis processing
            setTimeout(() => {
                // Generate comprehensive analysis
                const analysis = generateComprehensiveAnalysis();
                
                // Update analysis panel
                updateAnalysisPanel(analysis);
                
                // Restore button
                analyzeButton.innerHTML = '<i class="fas fa-search"></i> Run Deep Analysis';
                analyzeButton.disabled = false;
                
                showNotification("Deep analysis completed!");
            }, 2000);
        }
        
        // Export data
        function exportData() {
            if (capturedImages.length === 0) {
                alert("No data to export. Capture some images first.");
                return;
            }
            
            // Create export object
            const exportData = {
                app: "AI Body & Motion Analysis Scanner",
                exportDate: new Date().toISOString(),
                totalCaptures: capturedImages.length,
                captures: capturedImages.map(img => ({
                    timestamp: img.timestamp,
                    detectionMode: img.detectionMode,
                    analysis: img.analysis
                })),
                summary: generateComprehensiveAnalysis()
            };
            
            // Convert to JSON and download
            const dataStr = JSON.stringify(exportData, null, 2);
            const dataUri = 'data:application/json;charset=utf-8,'+ encodeURIComponent(dataStr);
            
            const exportFileDefaultName = `ai-scanner-export-${new Date().toISOString().slice(0, 10)}.json`;
            
            const linkElement = document.createElement('a');
            linkElement.setAttribute('href', dataUri);
            linkElement.setAttribute('download', exportFileDefaultName);
            linkElement.click();
            
            showNotification(`Exported ${capturedImages.length} captures as JSON`);
        }
        
        // Update analysis panel with current detection results
        function updateAnalysisPanel(analysisData = null) {
            // If no analysis data provided, generate based on current state
            if (!analysisData) {
                analysisData = generateComprehensiveAnalysis();
            }
            
            // Update the analysis results panel
            analysisResults.innerHTML = '';
            
            // Add each analysis item
            analysisData.forEach(item => {
                const analysisItem = document.createElement('div');
                analysisItem.className = 'analysis-item';
                analysisItem.innerHTML = `
                    <h3><i class="${item.icon}"></i> ${item.title}</h3>
                    <p>${item.description}</p>
                    <span class="status ${item.status}">${item.statusText}</span>
                `;
                
                analysisResults.appendChild(analysisItem);
            });
        }
        
        // Generate comprehensive analysis data
        function generateComprehensiveAnalysis() {
            // This is simulated analysis data
            // In a real implementation, this would be based on actual detection results
            
            const activities = ['walking', 'running', 'jumping', 'standing', 'cycling', 'fighting'];
            const randomActivity = activities[Math.floor(Math.random() * activities.length)];
            
            const objects = ['person', 'chair', 'bottle', 'cell phone', 'book', 'cup'];
            const randomObject = objects[Math.floor(Math.random() * objects.length)];
            
            return [
                {
                    title: "Body Pose Analysis",
                    icon: "fas fa-walking",
                    description: usePoseDetection ? 
                        `Detected ${Math.floor(Math.random() * 2) + 1} person(s) with ${Math.floor(Math.random() * 10) + 15} keypoints each. Posture is ${Math.random() > 0.5 ? 'balanced' : 'slightly imbalanced'}.` :
                        "Switch to pose detection mode for body analysis.",
                    status: usePoseDetection ? "detected" : "analyzing",
                    statusText: usePoseDetection ? "Active" : "Switch Mode"
                },
                {
                    title: "Motion Pattern Recognition",
                    icon: "fas fa-running",
                    description: `Detected activity: ${randomActivity}. Confidence: ${(Math.random() * 30 + 65).toFixed(1)}%. Motion vectors show ${Math.random() > 0.5 ? 'smooth' : 'jerky'} movement patterns.`,
                    status: "detected",
                    statusText: randomActivity.charAt(0).toUpperCase() + randomActivity.slice(1)
                },
                {
                    title: "Object Detection",
                    icon: "fas fa-cube",
                    description: usePoseDetection ? 
                        "Switch to object detection mode for detailed object analysis." :
                        `Detected ${Math.floor(Math.random() * 3) + 1} object(s) including ${randomObject}. Object tracking is ${Math.random() > 0.5 ? 'stable' : 'intermittent'}.`,
                    status: usePoseDetection ? "analyzing" : "detected",
                    statusText: usePoseDetection ? "Switch Mode" : "Active"
                },
                {
                    title: "Body Structure Analysis",
                    icon: "fas fa-heartbeat",
                    description: usePoseDetection ? 
                        `Body proportions: ${(Math.random() * 20 + 80).toFixed(1)}% symmetrical. Balance score: ${(Math.random() * 30 + 60).toFixed(1)}%. Suggested improvements: ${Math.random() > 0.7 ? 'Core strengthening' : 'Posture alignment'}.` :
                        "Switch to pose detection mode for body structure analysis.",
                    status: usePoseDetection ? "detected" : "analyzing",
                    statusText: usePoseDetection ? "Analyzed" : "Switch Mode"
                }
            ];
        }
        
        // Update pose analysis
        function updatePoseAnalysis(poses) {
            // In a real implementation, this would update specific pose analysis
            // For this demo, we'll just update periodically via updateAnalysisPanel()
        }
        
        // Update object analysis
        function updateObjectAnalysis(objects) {
            // In a real implementation, this would update specific object analysis
            // For this demo, we'll just update periodically via updateAnalysisPanel()
        }
        
        // Get current analysis for captured images
        function getCurrentAnalysis() {
            const activity = ['walking', 'running', 'jumping', 'fighting', 'cycling'][Math.floor(Math.random() * 5)];
            return {
                activity: activity,
                confidence: (Math.random() * 30 + 65).toFixed(1),
                objectsDetected: Math.floor(Math.random() * 3),
                postureScore: (Math.random() * 30 + 60).toFixed(1),
                symmetryScore: (Math.random() * 20 + 75).toFixed(1)
            };
        }
        
        // Show notification
        function showNotification(message) {
            // Create notification element
            const notification = document.createElement('div');
            notification.style.cssText = `
                position: fixed;
                top: 20px;
                right: 20px;
                background: linear-gradient(135deg, #0077b6, #0096c7);
                color: white;
                padding: 15px 20px;
                border-radius: 8px;
                box-shadow: 0 5px 15px rgba(0, 0, 0, 0.3);
                z-index: 1000;
                font-weight: 600;
                animation: slideIn 0.3s ease-out;
            `;
            
            notification.textContent = message;
            document.body.appendChild(notification);
            
            // Remove after 3 seconds
            setTimeout(() => {
                notification.style.animation = 'slideOut 0.3s ease-out forwards';
                setTimeout(() => {
                    document.body.removeChild(notification);
                }, 300);
            }, 3000);
        }
        
        // Add CSS for notification animation
        const style = document.createElement('style');
        style.textContent = `
            @keyframes slideIn {
                from { transform: translateX(100%); opacity: 0; }
                to { transform: translateX(0); opacity: 1; }
            }
            @keyframes slideOut {
                from { transform: translateX(0); opacity: 1; }
                to { transform: translateX(100%); opacity: 0; }
            }
        `;
        document.head.appendChild(style);
        
        // Simulated pose data for demo when TensorFlow.js models are not available
        function getSimulatedPoses() {
            const poseCount = Math.random() > 0.7 ? 2 : 1;
            const poses = [];
            
            for (let i = 0; i < poseCount; i++) {
                const offsetX = 100 + i * 200;
                const offsetY = 100 + Math.sin(Date.now() / 1000 + i) * 30;
                
                const keypoints = [
                    {name: 'nose', x: offsetX, y: offsetY, score: 0.9},
                    {name: 'left_eye', x: offsetX - 15, y: offsetY - 10, score: 0.85},
                    {name: 'right_eye', x: offsetX + 15, y: offsetY - 10, score: 0.85},
                    {name: 'left_ear', x: offsetX - 30, y: offsetY, score: 0.8},
                    {name: 'right_ear', x: offsetX + 30, y: offsetY, score: 0.8},
                    {name: 'left_shoulder', x: offsetX - 40, y: offsetY + 50, score: 0.9},
                    {name: 'right_shoulder', x: offsetX + 40, y: offsetY + 50, score: 0.9},
                    {name: 'left_elbow', x: offsetX - 70, y: offsetY + 80, score: 0.8},
                    {name: 'right_elbow', x: offsetX + 70, y: offsetY + 80, score: 0.8},
                    {name: 'left_wrist', x: offsetX - 90, y: offsetY + 110, score: 0.7},
                    {name: 'right_wrist', x: offsetX + 90, y: offsetY + 110, score: 0.7},
                    {name: 'left_hip', x: offsetX - 30, y: offsetY + 120, score: 0.9},
                    {name: 'right_hip', x: offsetX + 30, y: offsetY + 120, score: 0.9},
                    {name: 'left_knee', x: offsetX - 35, y: offsetY + 190, score: 0.85},
                    {name: 'right_knee', x: offsetX + 35, y: offsetY + 190, score: 0.85},
                    {name: 'left_ankle', x: offsetX - 40, y: offsetY + 260, score: 0.8},
                    {name: 'right_ankle', x: offsetX + 40, y: offsetY + 260, score: 0.8}
                ];
                
                // Animate the pose slightly
                keypoints.forEach(kp => {
                    if (kp.name.includes('wrist') || kp.name.includes('ankle')) {
                        kp.y += Math.sin(Date.now() / 300 + i) * 15;
                    }
                });
                
                poses.push({keypoints: keypoints, score: 0.8});
            }
            
            return poses;
        }
        
        // Simulated object data for demo when TensorFlow.js models are not available
        function getSimulatedObjects() {
            const objectCount = Math.floor(Math.random() * 3) + 1;
            const objects = [];
            const classes = ['person', 'bottle', 'cell phone', 'book', 'cup', 'chair'];
            
            for (let i = 0; i < objectCount; i++) {
                const width = 80 + Math.random() * 100;
                const height = 80 + Math.random() * 100;
                const x = 100 + i * 150 + Math.random() * 50;
                const y = 100 + Math.sin(Date.now() / 1000) * 30;
                
                objects.push({
                    bbox: [x, y, width, height],
                    class: classes[Math.floor(Math.random() * classes.length)],
                    score: 0.7 + Math.random() * 0.25
                });
            }
            
            return objects;
        }
        
        // Initialize the app when the page loads
        window.addEventListener('DOMContentLoaded', init);
    </script>
</body>
</html>
